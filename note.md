# 一、理论篇

## 1、高性能计算概述

### ①并行计算、高性能计算、超级计算

![并行计算、高性能计算与超级计算](img\并行计算、高性能计算与超级计算.png)

```txt
1、并行计算：在多个计算核心上同时计算同一任务，从广
义上说，任务中存在并行处理即为并行计算。
2、高性能计算：不能仅仅是多个核心同时运算，还要求高效发挥各
计算核心性能，需要程序员针对体系结构进行特殊优化，比如向量化、数据合并访存、提高cache命中率等;
3、超级计算：前提是高性能计算，计算时使用超过128个当代计算节点可称为超级计算。
```

### ②向量机与阵列机

#### Ⅰ、向量机（CPU）

##### (1)流水线技术

```txt
cpu流水线技术是一种将指令分解为多步，并让不同指令的各步操作重叠，从而实现几条指令并行处理，以加速程序运行过程的技术。指令的每步有各自独立的电路来处理，每完成一步，就进到下一步，而前一步则处理后续指令。
```

##### (2)向量机原理

```txt
向量机利用流水线技术，将计算机的计算单元和控制单元按序组装，利用部件分离和时间重叠思想，形成流水。只有在向量处理单元工作时，向量机才是SIMD计算机；而标量运算和分支处理时，向量机是SISD计算机。
```

#### Ⅱ、阵列机（GPU）

```txt
阵列机由一个控制器同时控制多个运算器，控制器进行指令解析和指令分发，而处理器只负责计算，处于相同控制器控制下的运算器执行相同指令操作。控制器执行两类指令：一类是控制指令，其本身解释执行；另一类是运算指令，控制器将该指令分发给所有处理器，所有处理器同时执行该条指令。显然，阵列机是一种典型的SIMD计算机。
```

![阵列机原理](img\阵列机原理.png)

## 2、GPU概述

### ①CPU与GPU

#### Ⅰ、设计目的

```txt
CPU:的设计目标是使执行单元能够以很低的延迟获得数据和指令，因此采用了复杂的控制逻辑和分支预测，以及大量的缓存来提高执行效率；
GPU:必须在有限的面积上实现超强的运算能力和极高的存储器带宽，因此需要大量执行单元来运行更多相对简单的线程，在当前线程等待数据时切换到另一个处于就绪状态等待计算的线程。

CPU对延迟更敏感，而GPU则侧重于提高整体的数据吞吐量。
```

![CPU与GPU对比](img\CPU与GPU对比.png)

#### Ⅱ、优化方式

```txt
CPU:向量机通过向量处理获得性能，因此优化ＣＰＵ程序时，向量化是至关重要的指标（编译时查看向量化报告开关-vec-report6，等级0~6自选）
GPU:阵列机是由同一个控制器控制下的多个处理单元组成的，各处理单元没有指令控制部件，在控制器控制下，各处理单元各自对分配的数据并发完成同一指令运算，阵列机的优化原则有数据对齐访问、避免分支分离等。
```

### ②CPU/GPU异构系统

```txt
CPU负责逻辑性较强的事务处理，GPU负责高密集度的浮点计算，在使用GPU计算前，CPU必须先通过北桥将数据传到GPU显存中；在GPU计算完成后，GPU再将结果数据返回给主机内存。CPU与GPU间的通信是必不可少的，由于接口PCL-E的通信带宽限制，优化数据通信开销是必须要考虑的问题。

GPU好比F1赛车，对跑道（环境）要求较高，但一旦跑起来速度非常快；而CPU相当一般家用轿车，一般公路即可满足条件。
```

![CPU与GPU对比](img\CPU与GPU对比.png)

## 3、GPU硬件架构

### ①kernel函数的硬件映射

```txt
grid（线程格）、block（线程块）、thread（线程）。三者是包含关系，大量的thread组成一个block，大量的block组成一个grid。当执行kernel函数时，一个核函数对应一个grid。在执行时，核函数映射到GPU，对应的block映射到SM(SMX,SMM)，thread
映射到SP（CUDA Core）。核函数中设置的block数量和thread数量都远远超过GPU硬件中的SMX和Core数量，GPU通过频繁的线程切换实现硬件资源的分时使用，切换开销极小，几乎可以忽略。
```

